{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Optimisation II:  A simple neural network \n",
    "\n",
    "### Nom(s): Sajid, Habibi\n",
    "### Pr√©nom(s): Badr, Issam\n",
    "### Groupe: B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  60000 images in the train set\n",
      "there are  10000 images in the test set\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load train data\n",
    "#\n",
    "Xtrain = np.load('train-images.npy')\n",
    "Xtrain = np.array([x.ravel()/255 for x in Xtrain])\n",
    "Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1],1)\n",
    "Ytrain = np.load('train-labels.npy')\n",
    "targets_train = []\n",
    "\n",
    "#\n",
    "# Convert digits to 10x1 vectors\n",
    "#\n",
    "for lab in Ytrain:\n",
    "    v      = np.zeros((10,1))\n",
    "    v[lab] = 1\n",
    "    targets_train+=[np.array(v)]\n",
    "\n",
    "#\n",
    "# Load test data\n",
    "#\n",
    "Xtest        = np.load('t10k-images.npy')\n",
    "Xtest        = np.array([x.ravel()/255 for x in Xtest])\n",
    "Xtest        = Xtest.reshape(Xtest.shape[0],Xtest.shape[1],1)\n",
    "Ytest        = np.load('t10k-labels.npy')\n",
    "targets_test = []\n",
    "\n",
    "#\n",
    "# Convert digits to 10x1 vectors\n",
    "#\n",
    "for lab in Ytest:\n",
    "    v = np.zeros((10,1))\n",
    "    v[lab]=1\n",
    "    targets_test+=[np.array(v)]\n",
    "#\n",
    "# Outputs\n",
    "#\n",
    "print('there are ',Xtrain.shape[0],'images in the train set')\n",
    "print('there are ',Xtest.shape[0],'images in the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the activation function\n",
    "\n",
    " The activation function defines the output of a node given a set of inputs. We use the <a href=\"https://en.wikipedia.org/wiki/Softmax_function\">softmax</a> function defined by\n",
    " \n",
    " $$\\sigma_{\\alpha} : \\mathbb{R}^p\\rightarrow [0,1]^p, \\quad \\mbox{ s.t.} \\quad[\\sigma_{\\alpha}(x)]_i=\\frac{e^{x_i+\\alpha_i}}{\\displaystyle{\\sum_{j=1}^{p}e^{x_j+\\alpha_j}}}\\quad \\forall i=1:p. $$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Nonlinear activation function\n",
    "#\n",
    "def softmax(x,alpha):\n",
    "    \"\"\"\n",
    "    Softmax unit activation function \n",
    "    x    : Numpy array\n",
    "    alpha: scalar\n",
    "    \"\"\" \n",
    "    #\n",
    "    # TO DO\n",
    "    #\n",
    "    value = np.exp(x+alpha) / np.sum(np.exp(x+alpha)) \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Example of a plot of the activation function\n",
    "#\n",
    "t     = np.arange(-5,5,0.1)\n",
    "alpha = np.arange(-50,50,1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(t,softmax(t,alpha))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of a simple neural network\n",
    "\n",
    "We use a one-layer fully-connected neural network with the <a href=\"https://en.wikipedia.org/wiki/Softmax_function\">softmax</a> activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x,W):\n",
    "    \"\"\"\n",
    "    # One-layer fully connected neural network\n",
    "    # x: image, i.e. 784x1 vector (28x28)\n",
    "    # W: weight matrices of shape 10x784   \n",
    "    \"\"\"\n",
    "    #\n",
    "    # TO DO: return pred (preticted probabilities) \n",
    "    #\n",
    "    pred = np.exp(x+alpha) / np.sum(np.exp(x+alpha)) \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the loss function\n",
    "\n",
    "The loss function is the <a href=\"https://en.wikipedia.org/wiki/Cross_entropy\">cross-entropy</a> defined by \n",
    "\n",
    "$$J(W)=-\\sum_{i=1}^N p_i \\log(q_i(W)),$$ where $N$ is the number of classes, $(p_i)_{i=1:N}$ are the probabilities of  a data from the training set to belong to a class (0 or 1 because the labels are known), and $(q_i(W))_{i=1:N}$ are the predicted probabilities from the model\n",
    "\n",
    "$$\\forall i=1:N, \\quad q_i(W)=[\\sigma_{\\alpha}(Wx)]_i.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Loss function = Cross-entropy\n",
    "#\n",
    "def cross_entropy(pred,target,x):\n",
    "    \"\"\"\n",
    "    pred:   predicted probabilities (q(W))\n",
    "    target: probabilities (p)\n",
    "    x:      image \n",
    "    \"\"\" \n",
    "    #\n",
    "    # TO DO: return ce,grad (cross_entropy, gradient of the cross-entropy)\n",
    "    #\n",
    "    ce = -np.sum(p*np.log(pred))\n",
    "    grad = \n",
    "        \n",
    "    return ce,grad\n",
    "#\n",
    "# Main function \n",
    "#\n",
    "def f(W,x,target):\n",
    "    \"\"\"\n",
    "    W:      weights\n",
    "    target: probabilities (p)\n",
    "    x:      image\n",
    "    \"\"\"\n",
    "    #\n",
    "    # TO DO: return ce, grad, pred (cross_entropy, gradient, predicted probabilities)\n",
    "    #\n",
    "    \n",
    "    return ce,grad,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Test information on the gradient with calls of f\n",
    "#\n",
    "\n",
    "# Define weight matrices\n",
    "W      = np.random.rand(10,Xtrain.shape[1])\n",
    "eps    = 1e-8\n",
    "d      = np.random.rand(10,Xtrain.shape[1])\n",
    "Wtilde = w+eps*d\n",
    "\n",
    "# Retrieve the information on the gradients\n",
    "res    = (f(Wtilde,Xtrain[0],targets_train[0])[0]-f(W,Xtrain[0],targets_train[0])[0])/eps\n",
    "print(res)\n",
    "\n",
    "g      = f(W,Xtrain[0],targets_train[0])[1]\n",
    "print(g.T.dot(d.reshape(7840,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Function to create batches of samples to be used later in the training phase\n",
    "#\n",
    "def create_batches(x,bs):\n",
    "    \"\"\"\n",
    "    x : set to be considered (array)\n",
    "    bs: batch size (scalar)\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    ind     = np.arange(x.shape[0])\n",
    "    random.shuffle(ind)\n",
    "    nbatch  = ind.shape[0]//bs\n",
    "    rest    = ind.shape[0]%bs\n",
    "    \n",
    "    for n in range(nbatch):\n",
    "        batches +=[ind[bs*n:bs*(n+1)]]\n",
    "    \n",
    "    # Put the remaining elements in a last batch\n",
    "    if rest !=0:        \n",
    "        batches += [ind[-rest:]]\n",
    "        \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history    = {}\n",
    "eta        = 1e-5 # learning rate\n",
    "momentum   = 0.   # momemtum factor\n",
    "N_EPOCHS   = 10  \n",
    "BatchSizes = [10000,1024,256] # try different batch sizes for the analysis\n",
    "\n",
    "for bs in BatchSizes:\n",
    "    #\n",
    "    # Sensitivity to the batch size to be investigated in the analysis\n",
    "    #\n",
    "    print('batch size=',bs)\n",
    "    \n",
    "    history[bs]={'train loss':[],'train acc':[],'test loss':[0], 'test acc':[0]}\n",
    "    \n",
    "    # Initialization of the weights\n",
    "    w = np.random.rand(10,Xtrain.shape[1])\n",
    "    \n",
    "    for n in range(N_EPOCHS):\n",
    "        # Minimization of the loss function\n",
    "        \n",
    "        Batches=create_batches(Xtrain,bs)\n",
    "        \n",
    "        for batch in Batches:\n",
    "            # Loop on the batches\n",
    "            #\n",
    "            # TO DO\n",
    "            #\n",
    "                   \n",
    "        # Test accuracy at the end of each epoch  \n",
    "        #\n",
    "        # TO DO\n",
    "        #\n",
    "        \n",
    "        print('Epoch number :', n+1,'test accuracy:',history[bs]['test acc'][n+1],'test loss',history[bs]['test loss'][n+1])\n",
    "        \n",
    "\n",
    "    print('\\n')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of the evolution of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bs in BatchSizes:\n",
    "       \n",
    "    n_batch = Xtrain.shape[0]//bs     \n",
    "    if Xtrain.shape[0]%bs!=0:\n",
    "        n_batch+=1\n",
    "        \n",
    "    E  = [n_batch*n for n in np.arange(N_EPOCHS+1)]\n",
    "    Ep = [str(n) for n in np.arange(N_EPOCHS+1)]\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.plot(history[bs]['train loss'],label = 'training loss')\n",
    "    plt.plot(E[1:],history[bs]['test loss'][1:],linewidth=2.5,label = 'test loss')\n",
    "    plt.xticks(E,Ep)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss Value')\n",
    "    #plt.ylim([0,np.max(history[bs]['test loss'])+2])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.title(f'model trained with a Batch size of {bs} samples and learning rate of {eta}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of the evolution of the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bs in BatchSizes:\n",
    "    print(bs)   \n",
    "    n_batch = Xtrain.shape[0]//bs     \n",
    "    if Xtrain.shape[0]%bs!=0:\n",
    "        n_batch+=1\n",
    "        \n",
    "    print(n_batch)\n",
    "    E=[n_batch*n for n in np.arange(N_EPOCHS+1)]\n",
    "    Ep = [str(n) for n in np.arange(N_EPOCHS+1)]\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.plot(history[bs]['train acc'] ,label  = 'training acuracy')\n",
    "    plt.plot(E[1:],history[bs]['test acc'][1:],linewidth=2.5,label = 'test acuracy')\n",
    "    plt.xticks(E,Ep)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.title(f'model trained with a Batch size of {bs} samples and learning rate of {eta}')\n",
    "    plt.ylim([0,1])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results\n",
    "\n",
    "Please provide your comments on the sensitivity of the results to the parameters involved in the learning process (batch size, learning rate, momentum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
